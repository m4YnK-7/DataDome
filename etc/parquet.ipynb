{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”´ Non-Optimized Processing Completed in 25.26 seconds\n",
      "ðŸ”´ Memory Used (Pandas): 2.14 MB\n",
      "\n",
      "ðŸ“Š Performance Comparison\n",
      "------------------------------------------------\n",
      "ðŸ”´ Pandas Processing Time: 25.26 sec\n",
      "ðŸ”´ Pandas Memory Usage   : 2.14 MB\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "csv_file = \"data.csv\"\n",
    "parquet_file = \"data.parquet\"\n",
    "cleaned_parquet_file = \"clean_data.parquet\"\n",
    "\n",
    "# Function to check memory usage\n",
    "def memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
    "\n",
    "### ðŸ“Œ Step 2: Non-Optimized Processing (Pandas)\n",
    "start_time_pandas = time.time()\n",
    "memory_start_pandas = memory_usage()\n",
    "\n",
    "# Load CSV using Pandas (Non-Optimized)\n",
    "df_pandas = pd.read_csv(csv_file, low_memory=False)\n",
    "\n",
    "# Cleaning using Pandas\n",
    "df_pandas = df_pandas.drop_duplicates()  # Remove duplicates\n",
    "df_pandas.fillna(df_pandas.mean(numeric_only=True), inplace=True)  # Fill NaNs for numeric columns\n",
    "df_pandas.fillna(df_pandas.mode().iloc[0], inplace=True)  # Fill NaNs for categorical columns\n",
    "\n",
    "# Outlier Removal (Z-score method)\n",
    "def remove_outliers(data, threshold=3):\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    return data[(np.abs(data - mean) / std) < threshold]\n",
    "\n",
    "for col in df_pandas.select_dtypes(include=[\"float64\", \"int64\"]).columns:\n",
    "    df_pandas[col] = remove_outliers(df_pandas[col])\n",
    "\n",
    "# Normalize Numeric Features\n",
    "numeric_cols = df_pandas.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "df_pandas[numeric_cols] = (df_pandas[numeric_cols] - df_pandas[numeric_cols].mean()) / df_pandas[numeric_cols].std()\n",
    "\n",
    "memory_end_pandas = memory_usage()\n",
    "time_pandas = time.time() - start_time_pandas\n",
    "\n",
    "print(f\"ðŸ”´ Non-Optimized Processing Completed in {time_pandas:.2f} seconds\")\n",
    "print(f\"ðŸ”´ Memory Used (Pandas): {memory_end_pandas - memory_start_pandas:.2f} MB\")\n",
    "\n",
    "\n",
    "\n",
    "### ðŸ“Š Step 5: Performance Comparison\n",
    "print(\"\\nðŸ“Š Performance Comparison\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"ðŸ”´ Pandas Processing Time: {time_pandas:.2f} sec\")\n",
    "print(f\"ðŸ”´ Pandas Memory Usage   : {memory_end_pandas - memory_start_pandas:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV to Parquet...\n",
      "Conversion complete!\n",
      "âœ… Optimized Processing (Dask + Parquet) Completed in 121.60 seconds\n",
      "âœ… Memory Used (Dask): 389.48 MB\n",
      "Cleaned dataset saved!\n",
      "âœ… Dask Processing Time  : 121.60 sec (ðŸ”¼ 0.21x Faster)\n",
      "âœ… Dask Memory Usage     : 389.48 MB (ðŸ”½ Less Memory Used)\n"
     ]
    }
   ],
   "source": [
    "### ðŸš€ Step 1: Convert CSV to Parquet (Fast Storage)\n",
    "print(\"Converting CSV to Parquet...\")\n",
    "df = pd.read_csv(csv_file, low_memory=False)  # Load CSV\n",
    "df.to_parquet(parquet_file, engine=\"pyarrow\")  # Convert to Parquet\n",
    "print(\"Conversion complete!\")\n",
    "\n",
    "### ðŸš€ Step 3: Optimized Processing (Dask)\n",
    "start_time_dask = time.time()\n",
    "memory_start_dask = memory_usage()\n",
    "\n",
    "# Load Parquet Using Dask (Optimized)\n",
    "df_dask = dd.read_parquet(parquet_file)\n",
    "\n",
    "# Data Cleaning using Dask\n",
    "df_dask = df_dask.drop_duplicates()\n",
    "\n",
    "# Fill NaNs for numeric and categorical columns\n",
    "for col in df_dask.columns:\n",
    "    if df_dask[col].dtype in [\"float64\", \"int64\"]:\n",
    "        df_dask[col] = df_dask[col].fillna(df_dask[col].mean())\n",
    "    else:\n",
    "        df_dask[col] = df_dask[col].fillna(df_dask[col].mode().compute()[0])\n",
    "\n",
    "# Outlier Removal (Z-score method)\n",
    "for col in df_dask.columns:\n",
    "    if df_dask[col].dtype in [\"float64\", \"int64\"]:\n",
    "        df_dask[col] = df_dask[col].map_partitions(remove_outliers)\n",
    "\n",
    "# Normalize Numeric Features\n",
    "df_dask = df_dask.assign(**{\n",
    "    col: df_dask[col].map_partitions(lambda x: (x - x.mean()) / x.std(), meta=(col, 'f8'))\n",
    "    for col in numeric_cols\n",
    "})\n",
    "\n",
    "\n",
    "# Compute results (converts Dask DataFrame to Pandas)\n",
    "df_dask = df_dask.compute()\n",
    "\n",
    "memory_end_dask = memory_usage()\n",
    "time_dask = time.time() - start_time_dask\n",
    "\n",
    "print(f\"âœ… Optimized Processing (Dask + Parquet) Completed in {time_dask:.2f} seconds\")\n",
    "print(f\"âœ… Memory Used (Dask): {memory_end_dask - memory_start_dask:.2f} MB\")\n",
    "\n",
    "### ðŸ“Œ Step 4: Save Cleaned Data (Optimized)\n",
    "df_dask.to_parquet(cleaned_parquet_file, engine=\"pyarrow\")\n",
    "print(\"Cleaned dataset saved!\")\n",
    "\n",
    "print(f\"âœ… Dask Processing Time  : {time_dask:.2f} sec (ðŸ”¼ {time_pandas / time_dask:.2f}x Faster)\")\n",
    "print(f\"âœ… Dask Memory Usage     : {memory_end_dask - memory_start_dask:.2f} MB (ðŸ”½ Less Memory Used)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
